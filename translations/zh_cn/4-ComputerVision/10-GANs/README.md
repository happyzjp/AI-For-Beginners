# 生成对抗网络



在上节中，我们了解了生成模型：能够生成与训练数据集中图像类似的新图像的模型。VAE 是生成模型的一个很好的例子。

## [ 课前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)



但是，如果我们尝试生成一些真正有意义的东西，比如分辨率合理的绘画，使用 VAE，我们会发现训练无法很好地收敛。对于此用例，我们应该了解专门针对生成模型的另一种架构 - 生成对抗网络或 GAN。

GAN 的主要思想是拥有两个将相互对抗的神经网络：

[![img](https://github.com/happyzjp/AI-For-Beginners/raw/main/translations/zh_cn/4-ComputerVision/10-GANs/images/gan_architecture.png)](https://github.com/happyzjp/AI-For-Beginners/blob/main/translations/zh_cn/4-ComputerVision/10-GANs/images/gan_architecture.png)

> 图片由 Dmitry Soshnikov 拍摄

> ✅ 一些词汇：
>
> - 生成器是一个网络，它接收一些随机向量，并生成图像作为结果
> - 鉴别器是一个网络，它接收图像，并判断它是真实图像（来自训练数据集），还是由生成器生成的。它本质上是一个图像分类器。

###  判别器



判别器的架构与普通图像分类网络没有区别。在最简单的情况下，它可以是全连接分类器，但很可能它是一个卷积网络。

> ✅ 基于卷积网络的 GAN 被称为 DCGAN

CNN 判别器由以下层组成：几个卷积+池化（空间尺寸减小），以及一个或多个全连接层以获取“特征向量”，最终的二元分类器。

> ✅ 在此上下文中，“池化”是一种减小图像尺寸的技术。“池化层通过将一层神经元簇的输出组合到下一层的单个神经元中来降低数据的维度。” - 来源

###  生成器



生成器稍微复杂一些。您可以将其视为反向判别器。从潜在向量（代替特征向量）开始，它有一个全连接层，将其转换为所需的尺寸/形状，然后进行反卷积+上采样。这类似于自动编码器的解码器部分。

> ✅ 由于卷积层是作为遍历图像的线性滤波器实现的，因此反卷积本质上类似于卷积，并且可以使用相同的层逻辑实现。

[![img](https://github.com/happyzjp/AI-For-Beginners/raw/main/translations/zh_cn/4-ComputerVision/10-GANs/images/gan_arch_detail.png)](https://github.com/happyzjp/AI-For-Beginners/blob/main/translations/zh_cn/4-ComputerVision/10-GANs/images/gan_arch_detail.png)

> 图片由 Dmitry Soshnikov 拍摄

###  训练 GAN



GAN 被称为对抗网络，因为生成器和判别器之间存在持续的竞争。在此竞争过程中，生成器和判别器都会得到改进，因此网络学会生成越来越好的图片。

训练分两个阶段进行：

- 训练判别器。此任务非常简单：我们通过生成器生成一批图像，将它们标记为 0，表示假图像，并从输入数据集（标签为 1，真图像）中获取一批图像。我们获得一些判别器损失，并执行反向传播。
- 训练生成器。这稍微有点棘手，因为我们不知道生成器的预期输出。我们采用由生成器和判别器组成的整个 GAN 网络，用一些随机向量对其进行馈送，并期望结果为 1（对应于真图像）。然后，我们冻结判别器的参数（我们不希望它在此步骤中接受训练），并执行反向传播。

在此过程中，生成器和判别器的损失都没有显著下降。在理想情况下，它们应该振荡，对应于两个网络都提高了它们的性能。

##  ✍️ 练习：GAN



- [TensorFlow/Keras 中的 GAN 笔记本](https://github.com/happyzjp/AI-For-Beginners/blob/main/translations/zh_cn/4-ComputerVision/10-GANs/GANTF.ipynb)
- [PyTorch 中的 GAN 笔记本](https://github.com/happyzjp/AI-For-Beginners/blob/main/translations/zh_cn/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN 训练中的问题



众所周知，GAN 训练起来特别困难。以下是一些问题：

- 模式崩溃。我们用这个术语表示生成器学会生成一张成功的图像来欺骗生成器，而不是生成各种不同的图像。
- 对超参数的敏感性。您经常会看到 GAN 根本不收敛，然后突然降低学习率导致收敛。
- 在生成器和判别器之间保持平衡。在许多情况下，判别器损失可以相对较快地降至零，这导致生成器无法进一步训练。为了克服这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者在损失已经太低的情况下跳过判别器训练。
- 高分辨率训练。与自动编码器一样，这个问题的触发原因是重建卷积网络的过多层会导致伪影。这个问题通常通过渐进式增长来解决，即首先在低分辨率图像上训练几层，然后“解除”或添加层。另一个解决方案是在层之间添加额外的连接，并一次训练多个分辨率——有关详细信息，请参阅这篇多尺度梯度 GAN 论文。

##  风格迁移



GAN 是生成艺术图像的绝佳方式。另一种有趣的技术是所谓的风格迁移，它采用一张内容图像，并以不同的风格重新绘制它，应用来自风格图像的滤镜。

它的工作方式如下：

- 我们从一个随机噪声图像开始（或从一个内容图像开始，但为了理解，从随机噪声开始更容易）
- 我们的目标是创建一个这样的图像，它既接近内容图像又接近风格图像。这将由两个损失函数决定：
  - 内容损失是基于 CNN 在某些层从当前图像和内容图像中提取的特征计算的
  - 样式损失使用 Gram 矩阵（在示例笔记本中了解更多详细信息）在当前图像和样式图像之间以一种巧妙的方式计算
- 为了使图像更平滑并去除噪点，我们还引入了变异损失，它计算相邻像素之间的平均距离
- 主要的优化循环使用梯度下降（或其他一些优化算法）调整当前图像以最小化总损失，总损失是所有三个损失的加权和。

## ✍️ 示例：样式迁移



## [ 课后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)



##  结论



在本课中，您学习了 GAN 以及如何训练它们。您还了解了这种类型的神经网络可能面临的特殊挑战，以及一些克服这些挑战的策略。

##  🚀 挑战



使用您自己的图像运行样式迁移笔记本。

##  复习与自学



作为参考，在这些资源中阅读有关 GAN 的更多信息：

- Marco Pasini，我训练 GAN 一年的 10 个教训
- StyleGAN，一个值得考虑的 GAN 架构
- [在 Azure ML 上使用 GAN 创建生成艺术](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

##  作业



重新访问与本课程相关的两个笔记本之一，并使用您自己的图像重新训练 GAN。你能创造出什么？