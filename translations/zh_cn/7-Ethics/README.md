# 道德和负责任的人工智能



您已经快完成本课程了，我希望到目前为止您已经清楚地看到，人工智能基于许多形式化的数学方法，这些方法使我们能够在数据中找到关系并训练模型以复制人类行为的某些方面。在历史的这个阶段，我们认为人工智能是一种从数据中提取模式并应用这些模式来解决新问题的非常强大的工具。

## [ 课前测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)



然而，在科幻小说中，我们经常看到人工智能对人类构成危险的故事。通常，这些故事都围绕着某种人工智能叛乱展开，即人工智能决定对抗人类。这意味着人工智能具有一定的情感或可以做出其开发者无法预见到的决定。

我们在本课程中了解到的人工智能只不过是大型矩阵运算。它是一个非常强大的工具，可以帮助我们解决问题，就像任何其他强大的工具一样——它可以用于好的和坏的目的。重要的是，它可能会被滥用。

## 负责任的人工智能原则





- 
- 
- 隐私和安全性有一些特定于人工智能的影响。例如，当我们使用一些数据来训练模型时，这些数据在某种程度上会“集成”到模型中。一方面，这增加了安全性和隐私性，另一方面 - 我们需要记住模型接受了哪些数据的训练。
- 包容性意味着我们构建人工智能不是为了取代人，而是为了增强人的能力，让我们的工作更具创造性。它还与公平性有关，因为在处理代表性不足的社区时，我们收集的大多数数据集都可能存在偏差，我们需要确保人工智能包含这些社区并正确处理这些社区。
- 透明度。这包括确保我们始终清楚人工智能的使用。此外，在可能的情况下，我们希望使用可解释的人工智能系统。
- 问责制。当人工智能模型做出一些决策时，并不总是清楚谁对这些决策负责。我们需要确保我们了解人工智能决策的责任归属。在大多数情况下，我们希望将人类纳入做出重要决策的循环中，以便追究实际人员的责任。

##  负责任的人工智能工具



Microsoft 已开发了负责任的人工智能工具箱，其中包含一组工具：

- 可解释性仪表盘 (InterpretML)
- 公平性仪表盘 (FairLearn)
- 错误分析仪表盘
- 包含以下内容的负责任 AI 仪表板
  - EconML - 因果分析工具，重点关注假设性问题
  - DiCE - 反事实分析工具，允许您查看需要更改哪些特征才能影响模型的决策

有关 AI 伦理的更多信息，请访问机器学习课程中的此课程，其中包括作业。

##  复习与自学



学习此学习路径以了解有关负责任 AI 的更多信息。

## [ 课后测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)
